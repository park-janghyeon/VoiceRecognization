# 🏆 KTL주관 2023 음성인식 어워드 3위 수상작

[한국산업기술시험원](https://www.ktl.re.kr/notice/notice_1/notice_announcement.do?temp_var=&menu_gubun=mid&menu_no=4&menu_no2=0&menu_no3=&params=&idx=20777&language=undefined&status=detail&searchOption6=9999,6&searchOption)

- **부문**:가전로봇 음성인식 챌린지
- **평가 장비**: 음성인식 챔버, 비전인식 챔버
- **평가 기준:** KS B 6970 (실내 서비스 로봇을 위한 음성인식 성능평가방법 표준)
- **챌린지 내용**:
    - 미션1 음성명령어 인식: 발화 거리 및 위치를 달리한 조건에서의 인식률, 거절률, 오인식률 평가
    - 미션2 응용미션: 가전로봇의 다양한 음성 명령 수행 능력 평가

## 목차

- [프로젝트 요약](#프로젝트-요약)
- [프로젝트 진행상의 난관](#프로젝트-진행상의-난관)
- [피드백](#피드백)

## 프로젝트 요약

- 준비기간: 2023.10.29 ~ 2023.11.03
- 기술 스택:  ![Python Version](https://img.shields.io/badge/python-3.11-blue.svg?&logo=python&logoColor=white)
![Platform](https://img.shields.io/badge/platform-raspberry%20pi%204-brightgreen.svg?&logo=raspberry-pi)
![Ubuntu Version](https://img.shields.io/badge/ubuntu-23.10-orange.svg?&logo=ubuntu&logoColor=white)
- **핵심 키워드**

오디오 데이터, 음성 인식, 데이터 인코딩, 샘플링 rate, 데이터 chunk, 실시간 API, Speech To Text, 유사도 비교, SequenceMatcher, 반복문 최적화

![image](https://github.com/typingmistake/VoiceRecognization/assets/102957984/0b2ab216-9921-4f3d-a588-a5a091465051)

```markdown
# 오디오 데이터 처리 프로세스

## 목적
- 오디오 데이터를 입력받아 DataSet 내의 주어진 음성과 매칭합니다.

## 주요 처리 과정
1. **음성 인식:** 입력된 오디오 데이터로부터 음성을 인식합니다.
2. **데이터 인코딩:** 인식된 데이터를 목적에 맞게 인코딩합니다. 인코딩 과정에서 다음 두 가지 주요 파라미터를 설정합니다.
   - `rate`: 분당 샘플링 횟수를 정의합니다.
   - `chunk`: 데이터 묶음의 단위입니다. 이 단위로 데이터 연산을 진행합니다.
3. **실시간 API 호출:** 인코딩된 데이터로 실시간 API 호출을 통해 Speech To Text 변환을 수행합니다.
4. **유사도 비교:** SequenceMatcher 알고리즘을 사용하여 인식된 텍스트를 제한된 DataSet과 비교합니다.
5. **결과 도출:**
   - DataSet 안의 모든 데이터와 비교하여 가장 높은 유사도를 가진 문장을 찾아냅니다.
   - 최적화를 위해, 인식된 텍스트가 DataSet에 포함되는 경우 반복문을 조기 종료하여 프로세스의 효율을 높입니다.
```

### 프로젝트 진행상의 난관

- 라즈베리파이 문제
    - 라즈베리파이 전원 공급 불량
    - 라즈베리파이 wifi 세팅
- 협업 시 역할 분배가 제대로 이뤄지지 않음.
- 프로젝트 진행시 팀원간의 커뮤니케이션
- 우분투 최신버전과 호환되지 않는 라이브러리 (ex. ROS)
- 가상 환경 이용의 필요성 (일부 라이브러리는 가상환경없이 설치 불가하였음)

### 피드백

**📌프로젝트 난관**

- **라즈베리파이 문제**
    - **라즈베리파이 전원 공급 불량** -> 제품불량을 의심하기보단 조립 잘했는지 재검토 필요.
    - **라즈베리파이 wifi 세팅** -> 유동적 wifi 환경에서 ssh 세팅을 어떻게 해야할지 해결방안 찾아야함.
- **협업 시 역할 분배가 제대로 이뤄지지 않음** -> 팀원의 전문성 정도를 먼저 파악하고 선호도를 고려 후 역할 재분배, 역할을 정확히 지정하는게 중요할듯. 정기적인 미팅.
- **팀원간의 커뮤니케이션 결여** -> 정기적인 미팅 약속하기.
- **우분투 최신버전과 호환되지 않는 라이브러리 (ex. ROS)** -> 우분투 LTS 버전 사용
- **가상 환경 이용의 필요성:**
    
    ```markdown
    sudo apt-get update
    sudo apt-get install python3-venv
    python3 -m venv myenv
    source myenv/bin/activate
    ```
    

📌**음성인식률 개선 방향**

- **현재 상태 (AS-IS)**
    - 인식률이 50%로 낮음: 100번의 음성 input 중 50번만 정확한 텍스트 output을 생성.
    - case0: 음성이 전혀 인식되지 않는 경우 발생.
    - case1: 음성의 일부가 누락: “에어컨 7번”의 입력에서 “에어컨”만 텍스트로 변환.
    - case2: 음성의 일부만 인식: “보일러작동시작”의 입력에서 “시작”만 텍스트로 변환.
- **목표 상태 (TO-BE)**
    - 인식률 향상: 입력된 음성의 100%에 수렴하게 텍스트로 변환되어야 함.
    - 오디오 데이터의 전체 내용을 정확하게 인식하고 변환하여, “에어컨 7번”과 “보일러작동시작”과 같은 입력이 완전한 문장으로 텍스트화됨.
    - 오류 발생 시 오디오 스트림을 효과적으로 재시작하여 연속성 있는 인식률 유지.
    - 시스템이 최적화되어 높은 신뢰도를 가진 음성 인식 결과를 제공.
- **원인 예측 및 해결책**
    
    1) Chunk 크기
    
    - **원인**: `chunk` 크기가 너무 크거나 너무 작으면, 오디오 데이터가 적절히 처리되지 않을 수 있습니다. 크기가 너무 크면 음성 인식이 느리게 진행되거나 누락될 수 있고, 너무 작으면 잡음이나 불완전한 단어로 인식될 수 있습니다.
    - **해결책**: 'chunk'를 입력 단위 시간인 5초에 맞춰 sample_rate*5로 사용했는데, 더 성공적인 결과를 얻었던 팀의 코드를 비교해 본 결과 chunk는 우리보다 낮았습니다. 저희의 현상황에서  chunk를 낮춘다면 api와의 데이터 전송이 더 빠르게 일어나고, 이에 맞춰 버퍼의 크기를 키운다면 데이터 손실 또한 적어질 수 있을 것입니다.
    
    2) 오디오 포맷과 샘플링 레이트
    
    - **원인**: `pyaudio.paInt16` 포맷과 `44100` 샘플링 레이트는 표준 설정입니다만, 실제 마이크와 오디오 환경에 따라 최적의 설정이 다를 수 있습니다.
    - **해결책**: 다른 오디오 포맷이나 샘플링 레이트를 시도해 보며, 마이크 사양에 가장 적합한 설정을 찾아봅니다.
    
    3) 인식 설정
    
    - **원인**: `interim_results` 설정이 `True`로 되어 있는데, 이는 최종 결과가 아닌 중간 결과를 반환하도록 설정되어 있습니다. 이는 불완전한 결과를 초래할 수 있습니다.
    - **해결책**: `interim_results`를 `False`로 설정하여 최종 결과만을 반환하도록 변경합니다.
    
    4) 향후업데이트 예정
